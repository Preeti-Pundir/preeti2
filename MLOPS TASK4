from PIL import Image
from keras.applications.vgg19 import preprocess_input
import base64
from io import BytesIO
import json
import random
import cv2
from keras.models import load_model
import numpy as np
from keras.preprocessing import image
model = load_model('C:/Users/lenovo/Desktop/mask_face/maskmodel.h5')
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')


def face_extractor(img):
    faces=face_cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=5)
    
    if faces is ():
        return None
    for (x,y,w,h) in faces:
        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)
        cropped_face = img[y:y+h, x:x+w]


    return cropped_face
video_capture = cv2.VideoCapture(0)
while True:
    _, frame = video_capture.read()
    face=face_extractor(frame)
    if type(face) is np.ndarray:
        face = cv2.resize(face, (224, 224))
        im = Image.fromarray(face, 'RGB')
        img_array = np.array(im)
        img_array = np.expand_dims(img_array, axis=0)
        pred = model.predict(img_array)
        print(pred)                   
        name="None matching"
        
        if(pred[0][0]==0.):
            name='Mask On'
            cv2.putText(frame,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)
        else:
            name='Mask Not On'
            cv2.putText(frame,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255,0,0), 2)              
    else:
        cv2.putText(frame,"No face found", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,155,45), 2)
    cv2.imshow('Video', frame)
    if cv2.waitKey(2)==27:
                break 
   
video_capture.release()
cv2.destroyAllWindows()
•	Its obvious class mode will be binary.
•	Lets plot the loss and accuracies which we will encounter during the epochs..:-
# loss
plt.plot(r.history['loss'], label='train loss')
plt.plot(r.history['val_loss'], label='val loss')
plt.legend()
plt.show()
plt.savefig('LossVal_loss')


# accuracies
plt.plot(r.history['accuracy'], label='train acc')
plt.plot(r.history['val_accuracy'], label='val acc')
plt.legend()
plt.show()
plt.savefig('AccVal_acc')

#saving the model
model.save('C:/Users/lenovo/Desktop/mask_face/mask_detection_model.h5'
After the model is trained it will be saved with your desired name.
•	Also you can tune the hyperparameters accordingly to increase the accuracy rate.
•	To automate the tuning of Hyper-parameters check out my blog on Integration of Machine Learning with DevOps. (click on the hyperlink)
•	Lets create our fully connected layer and our Model
prediction = Dense(len(folders), activation='sigmoid')(x)
model = Model(inputs=vgg.input, outputs=prediction)
model.summary()
model.compile(
  loss= 'binary_crossentropy',
  optimizer='adam',
  metrics=['accuracy']
)


The loss function here is binary_crossentropy as our model only have 2 classes.
•	Now I am doing some Augmentation with my dataset of Images for training the model more efficiently.
from keras.preprocessing.image import ImageDataGenerator


train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)


test_datagen = ImageDataGenerator(rescale = 1./255)


training_set = train_datagen.flow_from_directory(train_path,
                                                 target_size = (224, 224),
                                                 batch_size = 32,
                                                 class_mode = 'binary')


test_set = test_datagen.flow_from_directory(valid_path,
                                            target_size = (224, 224),
                                            batch_size = 32,
                                            class_mode = 'binary')


r = model.fit_generator(
  training_set,
  validation_data=test_set,
  epochs=7,
  steps_per_epoch=len(training_set),
  validation_steps=len(test_set)
)
•	Its obvious class mode will be binary.
•	Lets plot the loss and accuracies which we will encounter during the epochs..:-


